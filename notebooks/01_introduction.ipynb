{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "533c10f0-95ba-4684-a72d-fd52cef0d007"
    }
   },
   "source": [
    "# Lab 1: Data Providers and Preprocessing\n",
    "\n",
    "## Overview\n",
    "\n",
    "Today's exercises introduce you to the `mlp` package and data handling for machine learning. You'll implement variants of a `DataProvider` class that preprocesses data and serves it in batches for training neural networks.\n",
    "\n",
    "**Learning objectives:**\n",
    "- Understand how data flows through the `mlp` package\n",
    "- Implement data preprocessing and batch generation\n",
    "- Work with real datasets (MNIST digits, weather data)\n",
    "- Practice NumPy array manipulation and visualization\n",
    "\n",
    "**Prerequisites:** If you're new to Python/NumPy, consider reviewing:\n",
    "- [Stanford CS231n Python/NumPy tutorial](http://cs231n.github.io/python-numpy-tutorial/)\n",
    "- [Interactive Jupyter notebook version](https://github.com/kuleshov/teaching-material/blob/master/tutorials/python/cs228-python-tutorial.ipynb) (save to your `mlpractical/notebooks` directory)\n",
    "\n",
    "## Data Providers\n",
    "\n",
    "Data providers are classes that handle loading, preprocessing, and batching of datasets. Open the [`mlp.data_providers`](../mlp/data_providers.py) module in your browser to explore the code structure before starting the exercises.\n",
    "\n",
    "### Exercise 1: MNIST Data Visualization\n",
    "\n",
    "The `MNISTDataProvider` handles the [MNIST handwritten digit dataset](http://yann.lecun.com/exdb/mnist/), a standard machine learning benchmark. We'll use it to understand data loading and visualization.\n",
    "\n",
    "**Troubleshooting:** If you get `KeyError: 'MLP_DATA_DIR'`, ensure you've set the environment variable correctly during setup and activated the `mlp` conda environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "978c1095-a9ce-4626-a113-e0be5fe51ecb"
    }
   },
   "outputs": [],
   "source": [
    "# Setup for notebook\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mlp.data_providers as data_providers\n",
    "\n",
    "# If you encounter import errors, uncomment and modify the line below:\n",
    "# import sys; sys.path.append('/path/to/mlpractical')\n",
    "\n",
    "def show_single_image(img, title=\"\", fig_size=(3, 3)):\n",
    "    \"\"\"Display a single grayscale image.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=fig_size)\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    ax.set_title(title)\n",
    "    ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return fig, ax\n",
    "\n",
    "# Example: Display single MNIST images\n",
    "print(\"Loading MNIST validation data...\")\n",
    "mnist_dp = data_providers.MNISTDataProvider(\n",
    "    which_set='valid', batch_size=1, max_num_batches=3, shuffle_order=True)\n",
    "\n",
    "print(\"Displaying sample images:\")\n",
    "for i, (inputs, targets) in enumerate(mnist_dp):\n",
    "    # Reshape from 1D vector (784,) to 2D image (28, 28)\n",
    "    image = inputs.reshape(28, 28)\n",
    "    show_single_image(image, title=f'Digit: {targets[0]} (Image {i+1})')\n",
    "    \n",
    "print(\"Single image visualization complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Batch Visualization\n",
    "\n",
    "Now you'll work with batches of images rather than single examples.\n",
    "\n",
    "**Your task:**\n",
    "- Create an MNIST data provider that loads **5 batches** of **100 images** each\n",
    "- Display each batch as a **10×10 grid** of images\n",
    "- Print the batch number and first few target labels for each batch\n",
    "\n",
    "**Key concepts:**\n",
    "- **Batch processing:** Neural networks typically process multiple examples simultaneously for efficiency\n",
    "- **Data shapes:** \n",
    "  - `inputs`: shape `(batch_size, input_dim)` = `(100, 784)`\n",
    "  - `targets`: shape `(batch_size,)` = `(100,)`\n",
    "  - Each image: 784 pixels = 28×28 flattened\n",
    "- **Preprocessing:** Images are normalized to [0,1] from original [0,255] values\n",
    "\n",
    "**Implementation hints:**\n",
    "1. Use `batch_size=100` and `max_num_batches=5`\n",
    "2. Reshape input vectors: `inputs.reshape(batch_size, 28, 28)`\n",
    "3. Create a 10×10 grid: `int(batch_size**0.5)` gives you the grid size\n",
    "4. Use `plt.subplots()` for cleaner plotting code\n",
    "\n",
    "**Expected output:** 5 image grids, each showing 100 handwritten digits arranged in a 10×10 pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch_of_images(img_batch, fig_size=(8, 8)):\n",
    "    \"\"\"\n",
    "    Display a batch of images in a square grid.\n",
    "    \n",
    "    Args:\n",
    "        img_batch: numpy array of shape (batch_size, height, width)\n",
    "        fig_size: figure size for display\n",
    "    \"\"\"\n",
    "    raise NotImplementedError('Write me!')\n",
    "\n",
    "# Create data provider for batch processing\n",
    "batch_size = 100\n",
    "num_batches = 5\n",
    "\n",
    "#TODO: initialize the MNISTDataProvider class and iterate over batches\n",
    "# with the show_batch_of_images function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "d2d525de-5d5b-41d5-b2fb-a83874dba986"
    }
   },
   "source": [
    "### Exercise 2: One-Hot Encoding Implementation\n",
    "\n",
    "Currently, `MNISTDataProvider` returns integer targets (0-9 for digit classes). Neural networks typically work better with **one-hot encoded** targets, where each class is represented as a binary vector.\n",
    "\n",
    "**Concept: One-Hot Encoding**\n",
    "- **Integer encoding:** `[2, 2, 0, 1, 0]` (class indices)\n",
    "- **One-hot encoding:** Each class becomes a binary vector\n",
    "```python\n",
    "[[0, 0, 1],    # class 2\n",
    " [0, 0, 1],    # class 2  \n",
    " [1, 0, 0],    # class 0\n",
    " [0, 1, 0],    # class 1\n",
    " [1, 0, 0]]    # class 0\n",
    "```\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. **Implement `to_one_of_k` method** in the `MNISTDataProvider` class:\n",
    "   - Input: integer array of shape `(batch_size,)`\n",
    "   - Output: one-hot array of shape `(batch_size, num_classes)`\n",
    "   - Use `np.eye()` for efficient one-hot creation\n",
    "\n",
    "2. **Enable one-hot encoding** by uncommenting the overloaded `next` method in the class\n",
    "\n",
    "3. **Test your implementation** using the validation code below\n",
    "\n",
    "**Implementation hints:**\n",
    "- `np.eye(num_classes)[targets]` creates one-hot vectors efficiently\n",
    "- For MNIST: `num_classes = 10` (digits 0-9)\n",
    "- Each row should sum to 1, with exactly one element equal to 1\n",
    "\n",
    "**After making changes:** Restart your notebook kernel (`Kernel → Restart`) to reload the modified `mlp` package.\n",
    "\n",
    "**Expected behavior:** The test should pass without assertions failing, and you should see one-hot encoded target vectors printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your one-hot encoding implementation\n",
    "# Note: Run this AFTER implementing to_one_of_k and restarting the kernel\n",
    "\n",
    "import mlp.data_providers as data_providers\n",
    "import numpy as np\n",
    "\n",
    "print(\"Testing one-hot encoding implementation...\")\n",
    "\n",
    "# Create data provider with small batch for testing\n",
    "mnist_dp = data_providers.MNISTDataProvider(\n",
    "    which_set='valid', batch_size=5, max_num_batches=2, shuffle_order=False)\n",
    "\n",
    "for batch_num, (inputs, targets) in enumerate(mnist_dp, 1):\n",
    "    print(f\"\\nBatch {batch_num}:\")\n",
    "    print(f\"Target shape: {targets.shape}\")\n",
    "    print(f\"Target values:\\n{targets}\")\n",
    "    \n",
    "    # Validation checks\n",
    "    try:\n",
    "        # Check that values are binary (0 or 1)\n",
    "        assert np.all(np.logical_or(targets == 0., targets == 1.)), \\\n",
    "            \"Targets should only contain 0s and 1s\"\n",
    "        \n",
    "        # Check that each row sums to 1 (exactly one class per example)\n",
    "        row_sums = targets.sum(axis=1)\n",
    "        assert np.allclose(row_sums, 1.), \\\n",
    "            f\"Each row should sum to 1, got sums: {row_sums}\"\n",
    "        \n",
    "        # Check correct shape (should be 2D)\n",
    "        assert len(targets.shape) == 2, \\\n",
    "            f\"Targets should be 2D array, got shape: {targets.shape}\"\n",
    "        \n",
    "        # Check number of classes\n",
    "        assert targets.shape[1] == 10, \\\n",
    "            f\"Should have 10 classes for MNIST, got: {targets.shape[1]}\"\n",
    "        \n",
    "        print(\"All validation checks passed!\")\n",
    "        \n",
    "        # Show which digits these correspond to\n",
    "        digit_classes = np.argmax(targets, axis=1)\n",
    "        print(f\"Corresponding digit classes: {digit_classes}\")\n",
    "        \n",
    "    except AssertionError as e:\n",
    "        print(f\"Validation failed: {e}\")\n",
    "        print(\"Please check your to_one_of_k implementation\")\n",
    "        break\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"If all tests passed, your one-hot encoding is working correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "471093b7-4b94-4295-823a-5285c79d3119"
    }
   },
   "source": [
    "### Exercise 3: Custom Data Provider for Weather Data\n",
    "\n",
    "You'll create a `MetOfficeDataProvider` for South Scotland weather data, implementing time series prediction with sliding windows.\n",
    "\n",
    "**Dataset:** `data/HadSSP_daily_qc.txt`\n",
    "- **Format:** Each row = [year, month, day1, day2, ..., day31] (daily precipitation)\n",
    "- **Missing data:** `-99.9` values (non-existent days like Feb 31st)\n",
    "- **Task:** Predict next day's precipitation from previous days\n",
    "\n",
    "**Data processing pipeline:**\n",
    "1. **Load data** → 2. **Clean missing values** → 3. **Normalize** → 4. **Create windows** → 5. **Generate batches**\n",
    "\n",
    "---\n",
    "\n",
    "**Your implementation tasks:**\n",
    "\n",
    "- Implement the MetOfficeDataProvider class in `mlp/data_providers.py`. You only need to implement the `__init__()` function, following the instructions below:\n",
    "\n",
    "**Step 1: Data Loading & Cleaning**\n",
    "\n",
    "You should read all of the data from the file (`np.loadtxt` may be useful for this) and then filter out the -99.9 values and collapse the table to a one-dimensional array corresponding to a sequence of daily measurements for the whole period data is available for.\n",
    "\n",
    "**Step 2: Data Normalization**\n",
    "\n",
    "A common initial preprocessing step in machine learning tasks is to normalise data so that it has zero mean and a standard deviation of one. Normalise the data sequence so that its overall mean is zero and standard deviation one.\n",
    "\n",
    "**Step 3: Sliding Window Creation**\n",
    "\n",
    "Each data point in the data provider should correspond to a window of length specified in the __init__ method as window_size of this contiguous data sequence, with the model inputs being the first window_size - 1 elements of the window and the target output being the last element of the window. \n",
    "\n",
    "- **Window size 3 example:** `[1,2,3,4,5,6]` becomes:\n",
    "  - **Basic:** `([1,2]→3)`, `([4,5]→6)` \n",
    "  - **Sliding:** `([1,2]→3)`, `([2,3]→4)`, `([3,4]→5)`, `([4,5]→6)` ← **implement this**\n",
    "\n",
    "- While the basic method works, the sliding method provides more training data. Try to implement the sliding method.\n",
    "\n",
    "**Testing:** The cell below will validate your implementation with different window sizes and visualize the results.\n",
    "\n",
    "**After implementation:** Restart kernel to reload your changes before testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "c8553a56-9f25-4198-8a1a-d7e9572b4382"
    }
   },
   "outputs": [],
   "source": [
    "# Test your MetOfficeDataProvider implementation\n",
    "# Note: Run this AFTER implementing MetOfficeDataProvider and restarting kernel\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mlp.data_providers as data_providers\n",
    "import numpy as np\n",
    "\n",
    "print(\"Testing MetOfficeDataProvider implementation...\")\n",
    "\n",
    "# Test parameters\n",
    "batch_size = 3\n",
    "window_sizes = [2, 5, 10]\n",
    "\n",
    "# Test each window size\n",
    "for window_size in window_sizes:\n",
    "    print(f\"\\nTesting window_size = {window_size}\")\n",
    "    \n",
    "    try:\n",
    "        # Create data provider\n",
    "        met_dp = data_providers.MetOfficeDataProvider(\n",
    "            window_size=window_size, \n",
    "            batch_size=batch_size,\n",
    "            max_num_batches=2, \n",
    "            shuffle_order=False\n",
    "        )\n",
    "        \n",
    "        # Create visualization\n",
    "        fig, ax = plt.subplots(figsize=(10, 4))\n",
    "        ax.set_title(f'Weather Data Windows (size={window_size})')\n",
    "        ax.set_xlabel('Position in Window')\n",
    "        ax.set_ylabel('Normalized Precipitation')\n",
    "        \n",
    "        # Process batches\n",
    "        for batch_num, (inputs, targets) in enumerate(met_dp):\n",
    "            print(f\"  Batch {batch_num + 1}:\")\n",
    "            print(f\"    Input shape: {inputs.shape} (expected: {(batch_size, window_size-1)})\")\n",
    "            print(f\"    Target shape: {targets.shape} (expected: {(batch_size,)})\")\n",
    "            \n",
    "            # Validation checks\n",
    "            expected_input_shape = (batch_size, window_size - 1)\n",
    "            expected_target_shape = (batch_size,)\n",
    "            \n",
    "            assert inputs.shape == expected_input_shape, \\\n",
    "                f\"Input shape mismatch: got {inputs.shape}, expected {expected_input_shape}\"\n",
    "            assert targets.shape == expected_target_shape, \\\n",
    "                f\"Target shape mismatch: got {targets.shape}, expected {expected_target_shape}\"\n",
    "            \n",
    "            # Plot windows (input + target as continuous sequences)\n",
    "            for i in range(batch_size):\n",
    "                # Combine input and target for plotting\n",
    "                full_window = np.concatenate([inputs[i], [targets[i]]])\n",
    "                x_coords = range(len(full_window))\n",
    "                \n",
    "                # Plot the sequence\n",
    "                ax.plot(x_coords, full_window, '.-', alpha=0.7, \n",
    "                       label=f'Sample {i+1}' if batch_num == 0 else \"\")\n",
    "                \n",
    "                # Highlight the target (prediction point)\n",
    "                ax.plot(window_size-1, targets[i], 'ro', markersize=6)\n",
    "        \n",
    "        if window_size == window_sizes[0]:  \n",
    "            ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        \n",
    "        ax.axvline(x=window_size-1.5, color='gray', linestyle='--', alpha=0.5)\n",
    "        ax.text(window_size-2, ax.get_ylim()[1]*0.9, 'Inputs', ha='center', va='top')\n",
    "        ax.text(window_size-1, ax.get_ylim()[1]*0.9, 'Target', ha='center', va='top')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"Window size {window_size} test passed!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error with window_size {window_size}: {e}\")\n",
    "        print(f\"Please check your MetOfficeDataProvider implementation\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"If all tests passed, your MetOfficeDataProvider is working correctly!\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
